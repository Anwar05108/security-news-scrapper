Sophos Home protects every Mac and PC in your home 
Researchers at secure coding company Checkmarx have warned of porn-themed malware that’s been attracting and attacking sleazy internet users in droves.
Unfortunately, the side-effects of this malware, dubbed Unfilter or Space Unfilter, apparently involve plundering data from the victim’s computer, including Discord passwords, thus indirectly exposing the victim’s contacts – such as colleagues, friends and family – to spams and scams from cybercriminals who can now pose as someone those people know.
As we’ve mentioned many times before on Naked Security, cybercriminals love social networking and instant messaging passwords because it’s a lot easier to draw new victims in via a closed group than it is to con people using unsolicited messages over “open to all” channels such as email or SMS:
Instagram scammers as busy as ever: passwords and 2FA codes at risk


The scam in this case claims to offer software that can reverse the effects of TikTok’s Invisible filter, which is a visual effect that works a bit like the green screen or background filter that everyone seems to use these days in Zoom calls…
…except that the part of the image that’s blurred or made semi-transparent or translucent is you yourself, rather than the background.
If you put a sheet over your head, for example, like an archetypal comic book ghost, and then move around in a comic book ghost-like fashion (sound effects optional), the outline of the “ghost” will be discernible, but the background will typically still be vaguely, if blurrily, visible through the ghost’s outline, creating an amusing and intriguing effect.
Unfortunately, the idea of being pseudo-invisible has led to the so-called “TikTok Invisibility challenge”, where TikTok users are dared to film themselves live in various stages of undress, trusting in the Invisible filter to work well enough to stop their actual body being shown. 
Don’t do this. It should be obvious that there’s very little to be gained if it works, but an awful lot to lose (and not merely your dignity) if something goes wrong.
As you can probably imagine, this has led to sleazy online posts claiming to offer software that can reverse the effects of the Invisible filter after a video has been published, thus allegedly turning otherwise innocent-looking videos into NSFW porn clips.
That seems to be exactly the path that cybercriminals took in the attack outlined by Checkmarkx, where the crooks:
The final malware payload, obviously, could therefore be modified at will by the crooks by simply changing what gets served up when the bogus “unfilter” project is installed:
As mentioned above, the malware seen by Checkmarx seems to have been a variant of a data stealing “toolkit” variously known as WASP or W4SP that is disseminated via poisoned GitHub projects, and that budding cybercriminals can buy into for as little as $20.
Often, GitHub-based supply chain attacks rely on malicious packages with names that are easily confused with well-known, legitimate packages that developers might download by mistake, and the aim of the attack is therefore to poison one or more development computers inside a company, perhaps in the hope of subverting that company’s development process.
That way, the crooks hope to end up with malware (perhaps a completely different strain of malware) embedded into the official releases of software created by a legitimate company, thus not only getting someone else to package up their malware, but typically also to add a digital signature to it, and perhaps even to push it out automatically in the company’s next software update.
This results in a classic supply-chain attack, where you innocently and intentionally pull down malware from someone you already trust, instead of having to be tricked or cajoled into downloading it from someone or somewhere you’ve never heard of before.
LEARN MORE ABOUT SUPPLY-CHAIN ATTACKS AND HOW TO STOP THEM
Listen up 2 – CYBERSECURITY FIRST! How to protect yourself from supply chain attacks


In this attack, however, the criminals seemed to be targeting any and all individuals who installed the fake “unfilter” code, given that a “how to install packages from GitHub” video would be unnecessary for developers.
Developers would already be familiar with using GitHub and installating Python code, and might even have their suspicions increased by a package that went out of its way to state something that they would have considered obvious.
The malware unleashed in this case appears to have been intended to attack each victim individually, directly seeking out valuable data including Discord passwords, cryptocurrency wallets, stored payment card data, and more.
Remember: If in doubt/Leave it out.
Follow @NakedSecurity on Twitter for the latest computer security news.
Follow @NakedSecurity on Instagram for exclusive pics, gifs, vids and LOLs!
The onion-like levels of sleeze revealed by this story are mind boggling. I don’t suppose it’s worthwhile to hope people will rally around a call to a higher morality but so much trouble is avoided by living an upright life.
I wouldn’t say that “not seeking to turn other people’s innocent pics into pron” needs much of a “call to higher morality”, more like basic table stakes for life.
I’d hardly call posting naked pictures of yourself to a Social Media site (filter or no) is “innocent pics”.
No amount of great security practices can mitigate stupidity on those levels.
If the pictures you post don’t show you naked, then the issue of what you were wearing when they were taken should be irrelevant.
(We do clearly advice “don’t do this” in the article, just in case something does go wrong.)
LOL, app should have been called Dtowywhdty (do to others what you would have them do to you) or Instakarma 2.0
No sympathy for the users, nope, none at all.
Which users? The prurient ones who got directly infected by the crooks, or the ones who got hit up with spams and scans as a side-effect?
People that install an app to (supposedly) hack other photos.
I equate this (lightly) to someone who paid to dox/ddos/(abuse) others, and getting it done to themselves instead. Hmmm, to start a service that does that, hmmm….. :p
Comment * 
Name 
Email 
Website 
 



Δ