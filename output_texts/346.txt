Sophos Home protects every Mac and PC in your home 
Iâ€™M SORRY, DAVE, Iâ€™M AFRAIDâ€¦ SORRY, MY MISTAKE, I CAN DO THAT EASILY
No audio player below? Listen directly on Soundcloud.
With Doug Aamoth and Paul Ducklin. Intro and outro music by Edith Mudge.
You can listen to us on Soundcloud, Apple Podcasts, Google Podcasts, Spotify, Stitcher and anywhere that good podcasts are found. Or just drop the URL of our RSS feed into your favourite podcatcher.
READ THE TRANSCRIPT
DOUGÂ Â Patches aplenty, connected garage doors, and motherboard malfeasance. 
All that and more on the Naked Security podcast. 
[MUSICAL MODEM]
Welcome to the podcast, everybody. 
I am Doug Aamoth; he is Paul Ducklin. 
Paul, how do you do?
DUCKÂ Â I am still trying to make sense of when you said â€œconnected garage doorsâ€, Doug.
Because this is connectivity on a whole new scale!
DOUGÂ Â Oh, yes! 
What could possibly go wrong? 
Weâ€™ll get into thatâ€¦ 
We like to start the show with the This Week in Tech History segment. 
We have many optionsâ€¦ today we will spin the wheel. 
What happened this week? 
The first man in space, Yuri Gagarin, in 1961; Ronald Wayne leaves Apple and sells his stock for $800 in 1976 â€“ probably a bit of regret there; the germination of COBOL in 1959; the first Space Shuttle launch in 1981; the Apollo 13 rescue mission in 1970; Metallica sues Napster in 2000; and the first West Coast Computer Faire in 1977. 
Letâ€™s go ahead and spin the wheel here, and see where we land.
[FX: WHEEL OF FORTUNE]
DUCKÂ Â [CHEERING THE WHEEL] COBOL, COBOL, COBOL!
[FX: WHEEL SLOWS AND STOPS]
DOUGÂ Â And we got COBOL!
Congratulations, Paul â€“ good job. 
This week, in 1959, there was a meeting, and at the meeting were some very important and influential computing pioneers who discussed the creation of a common, business-friendly programming language. 
The one-and-only Grace Hopper suggested that the US Department of Defense fund such a language. 
And, luckily enough, a DOD computing director was at the same meeting, liked the idea, and agreed to fund it. 
And with that, COBOL was born, Paul.
DUCKÂ Â Yes!
COBOL: COmmon Business-Oriented Language. 
And it came out of a thing called CODASYL. 
[LAUGHS} Thatâ€™s the acronym to begin/end all acronyms: The Conference/Committee on Data Systems Languages. 
But it was an intriguing idea that, of course, has come full circle several times, not least with JavaScript in the browser. 
A language like FORTRAN (FORmula TRANslation) was very popular for scientific computing at the time. 
But every company, every compiler, every little group of programmers had their own version of FORTRAN, which was better than everybody elseâ€™s. 
And the idea of COBOL was, â€œWouldnâ€™t it be nice if you could write the code, and then you could take it to any compliant compiler on any system, and the code would, within the limits of the system, behave the same?â€
So it was a way of providing a cmmon, business-oriented languageâ€¦ exactly as the name suggests.
DOUGÂ Â Exactly!
Well-named! 
Alright, weâ€™ve come a long way (good job, everybody), including up to the most recent Patch Tuesday.
Weâ€™ve got a zero-day; weâ€™ve got two curious bugs; and weâ€™ve got about 90-some other bugs. 
But letâ€™s get to the good stuff, Paulâ€¦
Patch Tuesday: Microsoft fixes a zero-day, and two curious bugs that take the Secure out of Secure Boot

DUCKÂ Â Yes, letâ€™s just knock on the head the zero-day, which is CVE-2023-28252, if you want to search that one down.
Because thatâ€™s one that crooks obviously already know how to exploit. 
Itâ€™s a bug in a part of Windows that weâ€™ve seen bugs in before, namely the Common Log File System driver. 
And thatâ€™s a system driver that allows any service or app on your device to do system logging in (supposedly) a controlled, secure way.
You write your logsâ€¦ they donâ€™t get lost; not everyone invents their own way of doing it; they get properly timestamped; they get recorded, even if thereâ€™s heavy load; etc.
Unfortunately, the driver that processes these logsâ€¦ itâ€™s basically doing its stuff under the SYSTEM account. 
So if thereâ€™s a bug in it, when you log something in a way thatâ€™s not supposed to happen, usually what happens is that you have whatâ€™s called an Elevation of Privilege, or EoP. 
And somebody who a moment ago might have just been a GUEST user suddenly is running under the SYSTEM account, which basically gives them as-good-as total control over the system. 
They can load and unload other drivers; they can access pretty much all the files; they can spy on other programs; they can start and stop processes; and so on.
Thatâ€™s the 0-day. 
It only got rated Important by Microsoftâ€¦ I presume because itâ€™s not remote code execution, so it canâ€™t be used by a crook to hack into your system in the first place. 
But once theyâ€™re in, this bug could, in theory (and in practice, given that itâ€™s an O-day), be used by a crook whoâ€™s already in to get what are effectively superpowers on your computer.
DOUGÂ Â And then, if you take the Secure out of Secure Boot, what does it become, Paul? 
Justâ€¦
DUCKÂ Â â€œBootâ€, I suppose? 
Yes, these are two bugs that just intrigued me enough to want to focus on them in the article on Naked Security. (If you want to know everything about all the patches, go to news.sophos.com and read the SophosLabs report on these bugs.) 
I wonâ€™t read out the numbers, theyâ€™re in the articleâ€¦ they both are headlined with the following words: Windows Boot Manager Security Feature Bypass Vulnerability. 
And Iâ€™ll read out how Microsoft describes it:
An attacker who successfully exploited these vulnerabilities could bypass Secure Boot to run unauthorised code. 
To be successful, the attacker would need either physical access or administrator privilegesâ€¦
â€¦which I imagine they might be able to get through the bug we spoke about at the start. [LAUGHS]
DOUGÂ Â Exactly, I was just thinking that!
DUCKÂ Â But the thing about, â€œHey, guys, donâ€™t worry, theyâ€™d need physical access to your computerâ€ is, in my opinion, a little bit of a red herring, Doug.
Because the whole idea of Secure Boot is itâ€™s meant to protect you even against people who do get physical access to your computer, because it stops things like the so called â€œevil cleanerâ€ attackâ€¦
â€¦which is where youâ€™ve just left your laptop in your hotel room for 20 minutes while you nip down to breakfast.
Cleaners come into hotel rooms every day; theyâ€™re supposed to be there.
Your laptopâ€™s there; itâ€™s closed; you think, â€œThey donâ€™t know the password, so they canâ€™t log in.â€
But what if they could just pop the lid open, stick in a USB key, and power it up while they complete the cleaning of your roomâ€¦
â€¦so they donâ€™t need to spend any time actually doing the hacking, because thatâ€™s all automated. 
Close the laptop; remove the USB key. 
What if theyâ€™ve implanted some malware? 
Thatâ€™s whatâ€™s known in the jargon as a bootkit. 
Not a rootkit, even lower than that: a BOOT kit. 
Something that actually influences your computer between the time that the firmware is run and Windows itself actually starts. 
In other words, it completely subverts the underpinnings on which Windows itself bases the security thatâ€™s coming next. 
For example, what if it had logged your BitLocker keystrokes, so it now knew the password to unlock your whole computer for next time? 
And the whole idea of Secure Boot is it says, â€œWell, anything that isnâ€™t digitally signed by a key thatâ€™s been preloaded into your computer (into whatâ€™s called the Trusted Platform Module), any code that somebody introduces, whether theyâ€™re an evil cleaner or a well intentioned IT manager, simply wonâ€™t run.
Although Microsoft only rates these bugs Important because theyâ€™re not your traditional remote code execution exploits, if I were a daily-driver Windows user, I think Iâ€™d patch, if only for those alone.
DOUGÂ Â So, get patched up now! 
You can read about these specific items on Naked Security, and a broader article on Sophos News that details the 97 CVEs in total that have been patched. 
And letâ€™s stay on the patch train, and talk about Apple, including some zero-days, Paul.
Apple issues emergency patches for spyware-style 0-day exploits â€“ update now!

DUCKÂ Â These were indeed zero-days that were the only things patched in this particular update released by Apple.
As ever, Apple doesnâ€™t say in advance what itâ€™s going to do, and it doesnâ€™t give you any warning, and it doesnâ€™t say whoâ€™s going to get what whenâ€¦
â€¦just at the beginning of the Easter weekend, we got these patches that covered a WebKit zero-day. 
So, in other words, merely looking at a booby-trapped website could get remote code execution, *and* there was a bug in the kernel that meant that once you had pwned an app, you could then pwn the kernel and essentially take over the whole device.
Which basically smells of, â€œHey, browse to my lovely website. Oh, dear. Now Iâ€™ve got spyware all over your phone. And I havenâ€™t just taken over your browser, Iâ€™ve taken over everything.â€ 
And in true Apple fashionâ€¦ at first, there were updates against both of those bugs for macOS 13 Ventura (the latest version of macOS), and for iOS and iPad OS 16.
There were partial fixes â€“ theere were WebKit fixes â€“ for the two older versions of macOS, but no patches for the kernel level vulnerability.
And there was nothing at all for iOS and iPadOS 15. 
Does this mean that the older versions of macOS donâ€™t have the kernel bug? 
That they do have the kernel bug, but they just havenâ€™t been patched yet? 
Is iOS 15 immune, or is it needing a patch but theyâ€™re just not saying? 
And then, lo and behold, in the aftermath of the Easter weekend, [LAUGHS] suddenly three more updates came out that filled in all the missing pieces. 
Apple zero-day spyware patches extended to cover older Macs, iPhones and iPads

It indeed turned out that all supported iOSes and iPadOSes (which is versions 15 and 16), and all supported macOSes (that is versions 11, 12 and 13) contained both of these bugs. 
And now they all have patches against both of them. 
Given that this bug was apparently found by a combination of the Amnesty International Security Lab and the Google Threat Response Teamâ€¦
â€¦well, you can probably guess that it has been used for spyware in real life. 
Therefore, even if you donâ€™t think that youâ€™re the kind of person whoâ€™s likely to be at risk of that kind of attacker, what it means is that these bugs not only exist, they clearly seem to work pretty well in the wild.
So if you havenâ€™t done an update check on your Mac or your iDevice lately, please do so. 
Just in case you missed out.
DOUGÂ Â OK!
As we know, connected garage door companies code these garage doors with cybersecurity in mind. 
So itâ€™s shocking that something like this has happened, Paulâ€¦
Hack and enter! The â€œsecureâ€ garage doors that anyone can open from anywhere â€“ what you need to know

DUCKÂ Â Yes. 
In this case, Doug (and I feel weâ€™d better say the brand name: itâ€™s Nexx), they seem to have introduced a special form of cybersecurity.
Zero-factor authentication, Doug! 
Thatâ€™s where you take something that is not intended to be made public (unlike an email address or a Twitter handle, where you want people to know it), but that is not actually a secret. 
So, an example might be the MAC address of your wireless card. 
In this case, theyâ€™d given each of their devices a presumably unique device IDâ€¦
â€¦and if you knew what any deviceâ€™s ID was, that counted as basically username, password and login code all in one go.
DOUGÂ Â [GROAN] Thatâ€™s convenientâ€¦
DUCKÂ Â Even more convenient, Doug: thereâ€™s a hard coded password in the firmware of every device.
DOUGÂ Â Oh, there we go! [LAUGHS]
DUCKÂ Â [LAUGHS] Once someone knows what that magic password is, it allows them to log into the cloud messaging system that these devices use around the globe. 
What the researcher who did this found, because he had one of these devicesâ€¦
â€¦he found that while he was watching for his own traffic, which he would maybe expect to see, he got everyone elseâ€™s as well, including their device IDs.
DOUGÂ Â [BIGGER GROAN] Oh, my goodness!
DUCKÂ Â Just in case the device ID wasnâ€™t enough, they also happen to include your email address, your initial, and your family name in the JSON data as well. 
Just in case you didnâ€™t already know how to stalk the person back to where they lived.
So, you could either go round to their house and open their garage and then steal their stuff. (Oh, by the way, this also seems applied to their home alarm systems as well, so you could turn off the alarm before you opened the garage door.) 
Or, if you were of sufficiently evil intent, you could just randomly open peopleâ€™s garage doors wherever they lived, because apparently thatâ€™s terribly amusing. Doug.
DOUGÂ Â [IRONIC] The least that this researcher could have done would have been to alert the company, say, three-plus months ago, and give them time to fix this.
DUCKÂ Â Yes, that is about the least he could have done.
Which is exactly what he did do. 
And thatâ€™s eventually why, several months later (I think it was in January he first contacted them, and he just couldnâ€™t get them moving on this)â€¦
â€¦eventually he said, â€œIâ€™m just going to go public with this.â€ 
To back him up, the US CISA [Cybersecurity and Infrastructure Security Agency] actually put out a sort of APB on this saying, â€œBy the way, just so you know, this company isnâ€™t being responsive, and we donâ€™t really know what to advise you.â€ 
Well, my advice wasâ€¦ consider using good old fashioned physical keys; donâ€™t use the app. 
To be fair, although the researcher described the nature of the bugs, as I have described them to you  here, he didnâ€™t actually put out a proof-of-concept. 
It wasnâ€™t like he made it super-easy for everybody. 
But I think he felt that he almost had a duty of care to people who had this product to know that maybe they too, needed to lean on the vendor.
DOUGÂ Â Alright, this is a classic â€œweâ€™ll keep an eye on thatâ€ type of story. 
And a great reminder at the end of the articleâ€¦ you write, as the old joke puts it, â€œThe S in IoT stands for Securityâ€, which is very much the case.
DUCKÂ Â Yes, it is time that we put the S in IoT, isnâ€™t it? 
I donâ€™t know how many times weâ€™re going to be telling stories like this about IoT devicesâ€¦ every time we do it, we hope itâ€™s the last time, donâ€™t we? 
Hard coded passwords.
Replay attacks being possible, because thereâ€™s no cryptographic uniqueness in each request.
Leaking other peopleâ€™s data.
Including unnecessary stuff in requests and repliesâ€¦ if youâ€™ve got the device ID and youâ€™re trying to identify the device, you donâ€™t need to tell the device its ownerâ€™s email address every time you want the door to open!
Itâ€™s just not necessary, and if you donâ€™t give it out, then it canâ€™t leak!
[IRONIC] But other than that, Doug, I donâ€™t feel strongly about it.
DOUGÂ Â [LAUGHS] OK, very good. 
Our last story of the day, but certainly not the least.
Motherboard manufacturer MSI is having some certificate-based firmware headaches lately.
Attention gamers! Motherboard maker MSI admits to breach, issues â€œrogue firmwareâ€ alert

DUCKÂ Â Yes, this is a rather terrible story. 
Allegedly, a ransomware crew going by the name Money Message have breached MSI, the motherboard makers. (Theyâ€™re very popular with gamers because theyâ€™re very tweakable motherboards.)
The criminals claim to have vast quantities of data that theyâ€™re going to breach unless they get the money. 
They havenâ€™t got the actual data on their leak site (at least they hadnâ€™t when I looked last night, which was just before the deadline expired), but theyâ€™re claiming that they have MSI source code. 
Theyâ€™re claiming that they have the framework that MSI uses to develop BIOS or firmware files, so in other words theyâ€™re implying that theyâ€™ve already got the insider knowledge they need to be able to build firmware that will be in the right format. 
And they say, â€œAlso, we have private keys.â€
Theyâ€™re inviting us to infer that those private keys would allow them to sign any rogue firmware that they build, which is quite a worrying thing for MSI, whoâ€™ve kind of gone down the middle on this. 
They admitted the breach; theyâ€™ve disclosed it to the regulator; theyâ€™ve disclosed it to law enforcement; and thatâ€™s pretty much all theyâ€™ve said. 
What they *have* done is give advice that we strongly recommend you follow anyway, namely telling its customers:
Obtain firmware or BIOS updates only from MSIâ€™s official website, and do not use files from sources other than the official website.
Now, weâ€™d hope that you wouldnâ€™t go off-piste to go and get yourself potentially rogue firmware BLOBs anywayâ€¦ as some of our commenters have said, â€œWhat do people think when they do that?â€ 
But in the past, if you couldnâ€™t get them from MSIâ€™s site, you could at least perhaps rely on validating the digital certificate by yourself if you liked. 
So I think you should say what you usually do about watching this space, Dougâ€¦
DOUGÂ Â Letâ€™s keep an eye on this one then, too!
And it begs the question from one of our readers (I couldnâ€™t have said it better myself) on the MSI storyâ€¦ Peter asks:
Could MSI not revoke the certificate that was used to sign the files? 
So even if someone did download a file that had been compromised, it would then fail the certificate check? 
Or does it not work like that?
DUCKÂ Â Well, it does work like that in *theory*, Doug. 
But if you just blindly start refusing anybody whoâ€™s already got firmware that was signed with the now deprecated certificate, you do run the risk, essentially, of having people who have as good as â€œlocked their keys in the carâ€, if you know what I mean. 
For example, imagine that you just go, â€œRight! On every computer in the world from tomorrow, any MSI firmware signed with this key that has been compromised (if the crooks are telling the truth) just wonâ€™t work. Youâ€™ll have to get a new one.â€ 
Well, how are you going to boot up your computer to get online to get the new one? [LAUGHS]
DOUGÂ Â [LAUGHS] A slight problem!
DUCKÂ Â There is that chicken-and-egg problem. 
And this does not just apply to firmwareâ€¦ if youâ€™re too quick in blocking everybodyâ€™s access to files that are trustworthy but were signed with a certificate that has now become untrustworthy, you do risk potentially doing more harm than good. 
You need to leave a bit of an overlap period.
DOUGÂ Â Alright, excellent question, and excellent answer. 
Thank you very much, Peter, for sending that in. 
If you have an interesting story, comment or question youâ€™d like to submit, weâ€™d love to read it on the podcast. 
You can email tips@sophos.com, you can comment on any one of our articles, or you can hit us up on social: @nakedsecurity. 
Thatâ€™s our show for today; thanks very much for listening. 
For Paul Ducklin, Iâ€™m Doug Aamoth, reminding you until next time toâ€¦
BOTHÂ Â Stay secure!
[MUSICAL MODEM]
Follow @NakedSecurity on Twitter for the latest computer security news.
Follow @NakedSecurity on Instagram for exclusive pics, gifs, vids and LOLs!
â€œWell, how are you going to boot up your computer to get online to get the new one?â€
How would the computer know that the certificate has been revoked until it checks online?
At that point, it should essentially be told â€œHey, hereâ€™s a new certificate for youâ€ and then once it has the new one â€œGo ahead and invalidate that old certificate, as well.â€
I hear youâ€¦ I suppose I was just simplifying greatly for effect: I meant to make it clear that secure revocation of trust after a breach can be harder than you think because of â€œthe need for overlapâ€, as I perhaps rather too briefly put it verbally. (Look at how long it takes us to get rid of old cryptographic algorithms when they are past their sell by date.)
As you say, it is *theoretically* easy to fix this problem. 
But the original questioner asked, â€œWhy not just revoke the existing keys?â€ As you explain, that alone wonâ€™t work â€“ in your example, your algorithm explicitly requires a protocol that delays revoking the keys until after the new keys have been securely delivered, installed and blessed by the existing system. 
Presumably, your system would need the new certificate to be signed by the old keyâ€¦ yet that it the very key that has just been revoked *because it has already been compromised*. In other words, you have to give the revoked key a stay of execution while it â€œtrains its replacementâ€, as it were.)
Fair point. I figured they would already have some sort of â€œtrusted pipelineâ€ or â€œtrusted delivery systemâ€ for delivering software/firmware updates, but itâ€™s been well over a decade since I last built my own computer, so Iâ€™m not exactly well-informed on the subject. ğŸ™‚
Comment * 
Name 
Email 
Website 
 



Î”